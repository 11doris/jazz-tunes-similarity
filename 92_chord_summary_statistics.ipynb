{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from model.PrepareData import PrepareData\n",
    "import re\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.optimize import minimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [
    "topn = 30\n",
    "ngrams = [1,2,3,4]\n",
    "\n",
    "WIDTH = 400\n",
    "HEIGHT = 250\n",
    "SCALE = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "def get_ngram_string():\n",
    "    return \"ngrams-\" + \"-\".join([str(i) for i in ngrams])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "def raw_chords_to_df(tunes, remove_root=False):\n",
    "  tunes_chords = [item for tune in tunes for item in tune]\n",
    "\n",
    "  if remove_root:\n",
    "    tunes_chords = [re.sub('[A-G][#b]?', '*', chord) for chord in tunes_chords]\n",
    "    tunes_chords = [chord.replace('-', ' â€“ ') for chord in tunes_chords]\n",
    "\n",
    "  counts = Counter(tunes_chords)\n",
    "  _df = pd.DataFrame(counts.items(),\n",
    "                    columns=['chord', 'count']).sort_values(by='count', ascending=False)\n",
    "\n",
    "  return _df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "def plot_zipf(chords):\n",
    "    counter_of_words = chords.set_index('chord').to_dict(orient='dict')\n",
    "    counter_of_words = Counter(counter_of_words['count'])\n",
    "\n",
    "    word_counts = np.array(sorted(counter_of_words.values(), reverse=True))\n",
    "    frequency_rank = np.array(list(range(1, len(word_counts) + 1)))\n",
    "\n",
    "    df_zipf = pd.DataFrame({'word_counts': word_counts,\n",
    "                            'rank': frequency_rank})\n",
    "\n",
    "    fig = px.scatter(df_zipf,\n",
    "                     x='rank',\n",
    "                     y='word_counts',\n",
    "                     log_y=True,\n",
    "                     log_x=True,\n",
    "                     labels={\n",
    "                         \"word_counts\": \"Absolute Frequency\",\n",
    "                         \"rank\": \"Frequency Rank\",\n",
    "                     },\n",
    "                     width=WIDTH, height=HEIGHT,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={'text': f\"Zipf Plot for {chords_preprocess} Vocabulary<br><sup>n-grams={ngrams}</sup>\",\n",
    "               'font': {'size': 12}\n",
    "               },\n",
    "        yaxis={'dtick': 1, 'showline': True, 'linewidth': 1, 'linecolor': 'black', 'showgrid': True, 'showticklabels': True},\n",
    "        xaxis={'dtick': 1, 'showline': True, 'linewidth': 1, 'linecolor': 'black', 'showgrid': True, 'showticklabels': True},\n",
    "        paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        font={'size': 8},\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    for format in [\"pdf\"]:\n",
    "        fig.write_image(f\"images/92a_{chords_preprocess}_{get_ngram_string()}_zipf.{format}\")\n",
    "\n",
    "    return word_counts, frequency_rank\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "def loglik(b):\n",
    "    # Power law function\n",
    "    Probabilities = word_counts**(-b)\n",
    "\n",
    "    # Normalized\n",
    "    Probabilities = Probabilities/Probabilities.sum()\n",
    "\n",
    "    # Log Likelihoood\n",
    "    Lvector = np.log(Probabilities)\n",
    "\n",
    "    # Multiply the vector by frequencies\n",
    "    Lvector = np.log(Probabilities) * freq_of_word_counts\n",
    "\n",
    "    # LL is the sum\n",
    "    L = Lvector.sum()\n",
    "\n",
    "    # We want to maximize LogLikelihood or minimize (-1)*LogLikelihood\n",
    "    return(-L)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "def corpus_chord_ngram(obj, ngrams):\n",
    "    _df = pd.DataFrame(columns=['sectionid', 'chords'])\n",
    "    list_corpus_chords = []\n",
    "    list_sectionid = []\n",
    "\n",
    "    # for each unique section of a tune, process the chords\n",
    "    for _id, line in obj.df_section.iterrows():\n",
    "        sectionid = line['sectionid']\n",
    "        tune_n = obj.preprocess_input(line['chords'], ngrams=ngrams)\n",
    "\n",
    "        list_corpus_chords.append(tune_n)\n",
    "        list_sectionid.append(sectionid)\n",
    "\n",
    "    _df = pd.DataFrame(list(zip(list_sectionid, list_corpus_chords)),\n",
    "                       columns=['sectionid', 'chords'])\n",
    "    _df = _df.set_index('sectionid')\n",
    "    return _df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "def plot_distribution(df, root_removed=False):\n",
    "    df.sort_values(by=['count'], ascending=False, inplace=True)\n",
    "    df_top = df.head(topn)\n",
    "\n",
    "    if len(df_top) >= topn:\n",
    "        text = f'Only the top {topn} chord n-grams are shown.'\n",
    "    else:\n",
    "        text = f'All chord n-grams are shown.'\n",
    "\n",
    "    if root_removed:\n",
    "        text2 = f', Root removed.'\n",
    "    else:\n",
    "        text2 = ''\n",
    "\n",
    "    fig = px.bar(df_top,\n",
    "                 x='chord',\n",
    "                 y='count',\n",
    "                 log_y=True,\n",
    "                 labels={\n",
    "                     \"chord\": \"\",\n",
    "                     \"count\": \"Absolute Frequency\",\n",
    "                 },\n",
    "                 width=WIDTH, height=HEIGHT,\n",
    "                 )\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        yaxis={'showline': False, 'linewidth': 1, 'linecolor': 'black', 'showgrid': True, 'showticklabels': True},\n",
    "        xaxis={'showline': True, 'linewidth': 1, 'linecolor': 'black', 'showgrid': True, 'showticklabels': True, 'categoryorder':'total descending'},\n",
    "        title={'text': f\"Distribution of {chords_preprocess} n-grams{text2}<br><sup>n-grams={ngrams}. {text}</sup>\",\n",
    "               'font': {'size': 12},\n",
    "               'yanchor': 'top',\n",
    "               'pad': {'b': 100}\n",
    "               },\n",
    "        xaxis_title=\"\",\n",
    "        yaxis_title=\"Absolute Frequency\",\n",
    "\n",
    "        margin=dict(l=0, r=20, t=20, b=20),\n",
    "        font=dict(\n",
    "            size=8,\n",
    "        ),\n",
    "        plot_bgcolor=\"white\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    for format in [\"pdf\"]:\n",
    "        fig.write_image(f\"images/92_{chords_preprocess}_{get_ngram_string()}_{text2}_{text}.{format}\",\n",
    "                        width=WIDTH, height=HEIGHT,\n",
    "                        scale=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Corpus: 3225\n",
      "Test Corpus: 186\n",
      "Train Corpus: 3225\n",
      "Test Corpus: 186\n"
     ]
    }
   ],
   "source": [
    "summary = pd.DataFrame(columns=['vocab',\n",
    "                                'ngram',\n",
    "                                'total_tokens',\n",
    "                                'unique_tokens',\n",
    "                                'num_sections',\n",
    "                                'mean_tokens_per_section',\n",
    "                                'prop_vocab_corpus'])\n",
    "\n",
    "for vocab in ['chordsBasic', 'chordsSimplified', 'chordsFull']:\n",
    "    for ngram in [[1], [1,2], [1,2,3], [1,2,3,4]]:\n",
    "        prep = PrepareData(vocab, ngrams=ngram)\n",
    "        df = corpus_chord_ngram(prep, ngram)\n",
    "\n",
    "        data = list(df['chords'])\n",
    "\n",
    "        flat_list = [item for section in data for item in section]\n",
    "        total_tokens = len(flat_list)\n",
    "        unique_tokens = len(set(flat_list))\n",
    "        num_sections = len(data)\n",
    "        mean_tokens_per_section = sum([len(section) for section in data])/num_sections\n",
    "\n",
    "        summary.loc[len(summary)] = {\n",
    "            'vocab': vocab,\n",
    "            'ngram': ngram,\n",
    "            'total_tokens': total_tokens,\n",
    "            'unique_tokens': unique_tokens,\n",
    "            'num_sections': num_sections,\n",
    "            'mean_tokens_per_section': round(mean_tokens_per_section, 2),\n",
    "            'prop_vocab_corpus': round(100*(unique_tokens / total_tokens), 2)\n",
    "        }\n",
    "\n",
    "summary\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Full Chords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chords_preprocess = 'chordsFull'\n",
    "prep = PrepareData(chords_preprocess, ngrams=ngrams)\n",
    "df = corpus_chord_ngram(prep, prep.ngrams)\n",
    "df = df['chords']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Number of sections used for training: {len(prep.df_section)}\")\n",
    "\n",
    "print(f\"Number of total sections: {len(prep.df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Overview for Full Chords, any Root"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_chords = raw_chords_to_df(df)\n",
    "df_chords.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_chords.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_counts, freq_of_word_counts = plot_zipf(df_chords)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if False:\n",
    "    f,ax = plt.subplots()\n",
    "    ax.scatter(freq_of_word_counts, word_counts,\n",
    "               marker='.',\n",
    "               label = \"data\")\n",
    "    ax.set_xlabel('Log Frequency Rank of Token')\n",
    "    ax.set_ylabel('Log Absolute Frequency of Token')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    if ngrams == [1]:\n",
    "        c = 0.1 # for ngram=[1]\n",
    "        min_rank = 1\n",
    "        max_rank = -1\n",
    "    elif ngrams == [1,2]:\n",
    "        c = 0.8 # for ngram=[1,2]\n",
    "        min_rank = 10\n",
    "        max_rank = 1000\n",
    "    elif ngrams == [1,2,3]:\n",
    "        c = 2 # for ngram=[1,2,3]\n",
    "        min_rank = 10\n",
    "        max_rank = 4000\n",
    "    elif ngrams == [1,2,3,4]:\n",
    "        c = 4 # for ngram=[1,2,3,4]\n",
    "        min_rank = 10\n",
    "        max_rank = 10000\n",
    "\n",
    "    print(f'Limiting data fit to {min_rank} to {max_rank}')\n",
    "    word_counts = word_counts[min_rank:max_rank]\n",
    "    freq_of_word_counts = freq_of_word_counts[min_rank:max_rank]\n",
    "\n",
    "    s_best = minimize(loglik, [2])\n",
    "    print(s_best)\n",
    "    print(s_best.x[0])\n",
    "\n",
    "    #c = 0.1 # for ngram=[1]\n",
    "    #c = 0.8 # for ngram=[1,2]\n",
    "    #c = 4 # for ngram=[1,2,3]\n",
    "    #c = 5 # for ngram=[1,2,3,4]\n",
    "    alpha = r'$\\alpha$'\n",
    "    ax.plot(c*10**4 * word_counts**-s_best.x,\n",
    "            word_counts,\n",
    "            '--',\n",
    "            color=\"orange\",\n",
    "            lw=1,\n",
    "            label = f'fitted {alpha}')\n",
    "    ax.set_title(f'Zipf Law for {chords_preprocess}, ngrams={ngrams}\\nc={c}, {alpha}={round(s_best.x[0],2)}')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.savefig(f\"images/92_zipf_{chords_preprocess}_{get_ngram_string()}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(df_chords)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Overview for Full Chords, Roots removed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_noroot = raw_chords_to_df(df, remove_root=True)\n",
    "df_noroot.head(50)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_noroot.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(df_noroot, root_removed=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Simplified Chords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chords_preprocess = 'chordsSimplified'\n",
    "prep = PrepareData(chords_preprocess, ngrams=ngrams)\n",
    "df = corpus_chord_ngram(prep, prep.ngrams)\n",
    "df = df['chords']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Overview for Simplified Chords, any Root"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_chords = raw_chords_to_df(df)\n",
    "df_chords.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_counts, freq_of_word_counts = plot_zipf(df_chords)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if False:\n",
    "    f,ax = plt.subplots()\n",
    "    ax.scatter(freq_of_word_counts, word_counts,\n",
    "               marker='.',\n",
    "               label = \"data\")\n",
    "    ax.set_xlabel('Log Frequency Rank of Token')\n",
    "    ax.set_ylabel('Log Absolute Frequency of Token')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    if ngrams == [1]:\n",
    "        c = 0.04 # for ngram=[1]\n",
    "        min_rank = 1\n",
    "        max_rank = -1\n",
    "    elif ngrams == [1,2]:\n",
    "        c = 0.5 # for ngram=[1,2]\n",
    "        min_rank = 10\n",
    "        max_rank = 1000\n",
    "    elif ngrams == [1,2,3]:\n",
    "        c = 1 # for ngram=[1,2,3]\n",
    "        min_rank = 10\n",
    "        max_rank = 4000\n",
    "    elif ngrams == [1,2,3,4]:\n",
    "        c = 2 # for ngram=[1,2,3,4]\n",
    "        min_rank = 10\n",
    "        max_rank = 8000\n",
    "\n",
    "    print(f'Limiting data fit to {min_rank} to {max_rank}')\n",
    "    word_counts = word_counts[min_rank:max_rank]\n",
    "    freq_of_word_counts = freq_of_word_counts[min_rank:max_rank]\n",
    "\n",
    "    # determine alpha\n",
    "    s_best = minimize(loglik, [2])\n",
    "    print(s_best)\n",
    "    print(s_best.x[0])\n",
    "\n",
    "\n",
    "    alpha = r'$\\alpha$'\n",
    "    ax.plot(c*10**4 * word_counts**-s_best.x,\n",
    "            word_counts,\n",
    "            '--', color=\"orange\", lw=1, label = f'fitted {alpha}')\n",
    "    ax.set_title(f'Zipf Law for {chords_preprocess}, ngrams={ngrams}\\nc={c}, {alpha}={round(s_best.x[0],2)}')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.savefig(f\"images/92_zipf_{chords_preprocess}_{get_ngram_string()}.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(df_chords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Overview for Simplified Chords, Roots removed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_noroot = raw_chords_to_df(df, remove_root=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_noroot.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(df_noroot, root_removed=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Basic Chords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chords_preprocess = 'chordsBasic'\n",
    "prep = PrepareData(chords_preprocess, ngrams=ngrams)\n",
    "df = corpus_chord_ngram(prep, prep.ngrams)\n",
    "df = df['chords']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Overview for Basic Chords, any Root"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_chords = raw_chords_to_df(df)\n",
    "df_chords.head()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_counts, freq_of_word_counts = plot_zipf(df_chords)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if False:\n",
    "    f,ax = plt.subplots()\n",
    "    ax.scatter(freq_of_word_counts, word_counts,\n",
    "               marker='.',\n",
    "               label = \"data\")\n",
    "    ax.set_xlabel('Log Frequency Rank of Token')\n",
    "    ax.set_ylabel('Log Absolute Frequency of Token')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    if ngrams == [1]:\n",
    "        c = 0.03 # for ngram=[1]\n",
    "        min_rank = 1\n",
    "        max_rank = -1\n",
    "    elif ngrams == [1,2]:\n",
    "        c = 0.3 # for ngram=[1,2]\n",
    "        min_rank = 10\n",
    "        max_rank = 1000\n",
    "    elif ngrams == [1,2,3]:\n",
    "        c = 1 # for ngram=[1,2,3]\n",
    "        min_rank = 0\n",
    "        max_rank = 8000\n",
    "    elif ngrams == [1,2,3,4]:\n",
    "        c = 2 # for ngram=[1,2,3,4]\n",
    "        min_rank = 10\n",
    "        max_rank = 8000\n",
    "\n",
    "    print(f'Limiting data fit to {min_rank} to {max_rank}')\n",
    "    print(freq_of_word_counts[:5])\n",
    "    word_counts_all = word_counts\n",
    "    word_counts = word_counts[min_rank:max_rank]\n",
    "    freq_of_word_counts = freq_of_word_counts[min_rank:max_rank]\n",
    "    print(freq_of_word_counts[:5])\n",
    "\n",
    "    # determine alpha\n",
    "    s_best = minimize(loglik, [2])\n",
    "    print(s_best)\n",
    "    print(s_best.x[0])\n",
    "\n",
    "    #c = 0.03 # for ngram=[1]\n",
    "    #c = 0.3 # for ngram=[1,2]\n",
    "    #c = 2 # for ngram=[1,2,3]\n",
    "    #c = 5 # for ngram=[1,2,3,4]\n",
    "    alpha = r'$\\alpha$'\n",
    "    ax.plot(c*10**4 * word_counts_all**-s_best.x,\n",
    "            word_counts_all,\n",
    "            '--', color=\"orange\", lw=1, label = f'fitted {alpha}')\n",
    "    ax.set_title(f'Zipf Law for {chords_preprocess}, ngrams={ngrams}\\nc={c}, {alpha}={round(s_best.x[0],2)}')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.savefig(f\"images/92_zipf_{chords_preprocess}_{get_ngram_string()}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(df_chords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Overview for Basic Chords, Roots removed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_noroot = raw_chords_to_df(df, remove_root=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_noroot.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_distribution(df_noroot, root_removed=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}